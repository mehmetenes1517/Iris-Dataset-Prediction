{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "qxs21iX-A-nY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Iris(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.mdl1=nn.Sequential(\n",
        "        nn.Linear(4,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,3)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.mdl1(x)\n"
      ],
      "metadata": {
        "id": "kFl4k-Vq4Gif"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparing"
      ],
      "metadata": {
        "id": "nweO5OzuIRX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Iris.csv')\n",
        "x=torch.FloatTensor(np.stack([df['SepalLengthCm'].values,df['SepalWidthCm'].values,df['PetalLengthCm'].values,df['PetalWidthCm'].values],axis=1).reshape(-1,4))\n",
        "y=df['Species']\n",
        "y.replace({'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2},inplace=True)\n",
        "y=torch.LongTensor(y.values.reshape(-1,1))"
      ],
      "metadata": {
        "id": "tPSw9ujs7QsJ"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "a1DKRVgUBKGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mdl1=Iris()\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(mdl1.parameters(),lr=0.001)\n",
        "epochs=3000\n",
        "losses=[]"
      ],
      "metadata": {
        "id": "tdl5gO3VBA7_"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "  predict_y=mdl1(x)\n",
        "  loss=criterion(predict_y,y.squeeze())\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  #backprop\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "eLE9qNP3Bz2C"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=mdl1(x)\n",
        "correct=0\n",
        "for i in range(150):\n",
        "  print(f'real : {y[i][0]} | predict : {predictions[i].argmax().item()}')\n",
        "  if y[i][0]==predictions[i].argmax().item():\n",
        "    correct+=1\n",
        "print(f'accuracy : {100*(correct/150)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIPB8jzoD36A",
        "outputId": "3398909d-8b80-44d9-8464-bae999f4d854"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 0 | predict : 0\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 2\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 1 | predict : 1\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 1\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "real : 2 | predict : 2\n",
            "accuracy : 98.66666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  a=float(input('SepalLengthCm :'))\n",
        "  b=float(input('SepalWidthCm  :'))\n",
        "  c=float(input('PetalLengthCm :'))\n",
        "  d=float(input('PetalWidthCm  :'))\n",
        "  if a==0 and  b==0 and c==0 and d==0:\n",
        "    break\n",
        "  pred=mdl1(torch.tensor([[a,b,c,d]]))[0].argmax().item()\n",
        "  if pred==0:\n",
        "    pred='Iris-setosa'\n",
        "  elif pred==1:\n",
        "    pred='Iris-versicolor'\n",
        "  else:\n",
        "    pred='Iris-virginica'\n",
        "\n",
        "  print(f'{pred}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtwV6raIEKc0",
        "outputId": "9b28b76a-924b-4c68-cce4-009b645ba92e"
      },
      "execution_count": 124,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SepalLengthCm :7.7\n",
            "SepalWidthCm  :3.8\n",
            "PetalLengthCm :6.7\n",
            "PetalWidthCm  :2.2\n",
            "Iris-virginica\n",
            "SepalLengthCm :6.6\n",
            "SepalWidthCm  :3.0\n",
            "PetalLengthCm :4.4\n",
            "PetalWidthCm  :1.4\n",
            "Iris-versicolor\n",
            "SepalLengthCm :5.2\n",
            "SepalWidthCm  :3.4\n",
            "PetalLengthCm :1.4\n",
            "PetalWidthCm  :0.2\n",
            "Iris-setosa\n",
            "SepalLengthCm :0\n",
            "SepalWidthCm  :0\n",
            "PetalLengthCm :0\n",
            "PetalWidthCm  :0\n"
          ]
        }
      ]
    }
  ]
}